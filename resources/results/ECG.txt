multi_step_lstm_config = {  'batch_size': 370,
                            'n_epochs': 100,
                            'dropout': 0.1,
                            'look_back': 3,
                            'look_ahead': 1,
                            #'layers':{'input': 1, 'hidden1':20, 'hidden2':5,  'output': 1},
                            #'layers':{'input': 1, 'hidden1': 200, 'hidden2': 80, 'hidden3': 40, 'hidden4': 10,'output': 1},
                            'layers': {'input': 1, 'hidden1': 60, 'hidden2': 60, 'output': 1},
                            'loss': 'mse',
                            #'optimizer': 'adam',
                            'train_test_ratio' : 0.7,
                            'shuffle': False,
                            'validation': True,
                            'learning_rate': .1,
                            'patience': 5,
                           }
#

2017-05-25 19:47:03,117. 
2017-05-25 19:48:07,438. ----------------------------------------------------
2017-05-25 19:48:07,438. Run id ECG_may25
2017-05-25 19:48:07,438.  HYPERPRAMRAMS : {'layers': {'input': 1, 'hidden1': 60, 'output': 1, 'hidden2': 60}, 'loss': 'mse', 'shuffle': False, 'learning_rate': 0.1, 'look_ahead': 1, 'batch_size': 367, 'epochs': 100, 'patience': 5, 'experiment_id': 'ECG_may25', 'data_folder': 'resources/data/discords/ECG/', 'validation': True, 'look_back': 3, 'dropout': 0.1}
2017-05-25 19:48:07,477. StatefulMultiStepLSTM LSTM Model Info: {'layers': {'input': 1, 'hidden1': 60, 'output': 1, 'hidden2': 60}, 'loss': 'mse', 'learning_rate': 0.1, 'look_ahead': 1, 'batch_size': 367, 'self': <models.lstm.StatefulMultiStepLSTM object at 0x7f0806529ad0>, 'look_back': 3, 'dropout': 0.1}
2017-05-25 19:48:08,480. Compilation Time : 0.0295031070709
2017-05-25 19:48:08,532. Training...
2017-05-25 19:49:48,182. Training duration (s) : 99.6501569748
2017-05-25 19:49:48,184. Training Loss per epoch: [0.55872116284444928, 0.10457791516091675, 0.067016234155744314, 0.057828545104712248, 0.05204383737873286, 0.047162168077193201, 0.045413329033181071, 0.042435569106601179, 0.041454130841884762, 0.039705869741737843, 0.038634089403785765, 0.038246951124165207, 0.036722338991239667, 0.03635885362746194, 0.036253392754588276, 0.035421852837316692, 0.034215209365356714, 0.034161816525738686, 0.034012557996902615, 0.033093158039264381, 0.032724166405387223, 0.032513551705051214, 0.032073216745629907, 0.031986184534616768, 0.031767797074280679, 0.031258077244274318, 0.030985285062342882, 0.031110135081689805, 0.03001427004346624, 0.030868596280924976, 0.029392593598458916, 0.029568896221462637, 0.029714780044741929, 0.030013445124495775, 0.029147389810532331, 0.029991241521202028, 0.029837700538337231, 0.02924654254456982, 0.028635106980800629, 0.028194105776492506, 0.02795435837469995, 0.027546933852136135, 0.028389697021339089, 0.028067529608961195, 0.028210861899424344, 0.027810225612483919, 0.027833996340632439, 0.027227633108850569, 0.027405751403421164, 0.028011017944663763, 0.028035232564434409, 0.027443925791885704, 0.027250932587776333, 0.02690967993112281, 0.026667787111364305, 0.026397937559522688, 0.027005757379811257, 0.026366875041276217, 0.026358969509601593, 0.026554071460850537, 0.02654268394690007, 0.026601061399560422, 0.026105533295776695, 0.026590682100504637, 0.026031712652184069, 0.026285910455044359, 0.026163112372159958, 0.026235363155137748, 0.025775794347282499, 0.026105078053660691, 0.02618950919713825, 0.02627952751936391, 0.025242962641641498, 0.025675606040749699, 0.02553815086139366, 0.025428920343983918, 0.026057191542349756, 0.025276521104387939, 0.025727497879415751, 0.025833005551248789, 0.025545764539856464, 0.024913961242418736, 0.025371566589456052, 0.025458113930653781, 0.025043471250683069, 0.025050090800505131, 0.025874884566292167, 0.024629791674669832, 0.024817176745273173, 0.024441996589303017, 0.024793352989945561, 0.024595500726718456, 0.025022312125656754, 0.025320887623820454, 0.025987686996813864, 0.025039333151653409]
2017-05-25 19:49:48,184. Validation  Loss per epoch: [0.12070849041144054, 0.083795296649138137, 0.053454022854566574, 0.043931937466065087, 0.037748670826355614, 0.033440424129366875, 0.030588350569208462, 0.028598691026369732, 0.027316326275467873, 0.025970845172802608, 0.025327228630582493, 0.024309902762373287, 0.023588409647345543, 0.023030957207083702, 0.022424312308430672, 0.022149346147974331, 0.02143183598915736, 0.021313481032848358, 0.020698507626851399, 0.020431414867440861, 0.020510056366523106, 0.020070519919196766, 0.019857022290428478, 0.01970260279874007, 0.019518374775846798, 0.019474354262153309, 0.019328666230042774, 0.01925222637752692, 0.018761839096744854, 0.018594160055120785, 0.018431562619904678, 0.018616259098052979, 0.018090091335276764, 0.01817856418589751, 0.01806986176719268, 0.017945011146366596, 0.018033495172858238, 0.017833856555322807, 0.017762108705937862, 0.01771169373144706, 0.017852255764106911, 0.017447597347199917, 0.017306759332617123, 0.01722453876088063, 0.017295911597708862, 0.017181867423156898, 0.017044364474713802, 0.016988129355013371, 0.016934295805792015, 0.017006604621807735, 0.016864374590416748, 0.01681035788108905, 0.016799413599073887, 0.016716502917309601, 0.016655058289567631, 0.016697670022646587, 0.016558076255023479, 0.016679566353559494, 0.016514216239253681, 0.01651094698657592, 0.016514585042993229, 0.016616239833335083, 0.016519256867468357, 0.016349685378372669, 0.016300332732498646, 0.016356644220650196, 0.016305157914757729, 0.016281802207231522, 0.016113582688073318, 0.016349435473481815, 0.016200797011454899, 0.016028850339353085, 0.016110950460036595, 0.016106128382186096, 0.015999687214692433, 0.01592606430252393, 0.015891872346401215, 0.015975183186431725, 0.016035335448880989, 0.015858178958296776, 0.015826476116975147, 0.015916249714791775, 0.015710015781223774, 0.015751366813977558, 0.015592077126105627, 0.015643136265377205, 0.015637398386994999, 0.015676719757417839, 0.015604765154421329, 0.01545413862913847, 0.015701294255753357, 0.015656158017615478, 0.015522774308919907, 0.015540394311149916, 0.015636792095998924, 0.015482779902716478]
2017-05-25 19:49:50,952. Validation2 Loss 0.102771230896
2017-05-25 19:49:51,094. Test Loss 0.102429188943
2017-05-25 19:49:51,642. Train RMSE on 1 timestep prediction 0.020152
2017-05-25 19:49:51,643.  Train RMSE Naive One Timestep Shift 0.020917
2017-05-25 19:49:55,995. Validation1 RMSE on 1 timestep prediction 0.019146
2017-05-25 19:49:55,995.  Validation1 RMSE Naive One Timestep Shift 0.020202
2017-05-25 19:49:58,076. Validation2 RMSE on 1 timestep prediction 0.049309
2017-05-25 19:49:58,076.  Validation2 RMSE Naive One Timestep Shift 0.035025
2017-05-25 19:50:17,017. Test RMSE on 1 timestep prediction 0.049226
2017-05-25 19:50:17,017.  Test RMSE Naive One Timestep Shift 0.035025
2017-05-25 19:50:23,306. -------------------------run complete----------------------------------------------


*********************************************************************************************************************************************************************
Lookahead 5


run_config = { 'Xserver' : True,
               'log_file' : 'logs/run.log',
               'experiment_id' : "ECG_may25",
               #'data_folder': 'resources/data/nab/nab_machine_temperature/',
               #'data_folder': 'resources/data/discords/space_shuttle/',
               #'data_folder': 'resources/data/discords/dutch_power/',
               'data_folder': 'resources/data/discords/ECG/',
               'save_figure': True
               }

opt_config = { 'Xserver' : True,
               'log_file' : '../logs/opt.log',
               'opt_run_id': "machine_temp_may24",
               'data_folder': '../resources/data/discords/dutch_power/',
               'save_figure': True,
               'model': 'stateful',
               'max_iter': 3,
                'initial_evals': 1
               }

multi_step_lstm_config = {  'batch_size': 370,
                            'n_epochs': 100,
                            'dropout': 0.1,
                            'look_back': 3,
                            'look_ahead': 5,
                            #'layers':{'input': 1, 'hidden1':20, 'hidden2':5,  'output': 1},
                            #'layers':{'input': 1, 'hidden1': 200, 'hidden2': 80, 'hidden3': 40, 'hidden4': 10,'output': 1},
                            'layers': {'input': 1, 'hidden1': 60, 'hidden2': 60, 'output': 1},
                            'loss': 'mse',
                            #'optimizer': 'adam',
                            'train_test_ratio' : 0.7,
                            'shuffle': False,
                            'validation': True,
                            'learning_rate': .1,
                            'patience': 5,
                           }
#

2017-05-25 20:18:40,311. Run id ECG_may25
2017-05-25 20:18:40,312.  HYPERPRAMRAMS : {'layers': {'input': 1, 'hidden1': 60, 'output': 1, 'hidden2': 60}, 'loss': 'mse', 'shuffle': False, 'learning_rate': 0.1, 'look_ahead': 5, 'batch_size': 363, 'epochs': 100, 'patience': 5, 'experiment_id': 'ECG_may25', 'data_folder': 'resources/data/discords/ECG/', 'validation': True, 'look_back': 3, 'dropout': 0.1}
2017-05-25 20:18:40,352. StatefulMultiStepLSTM LSTM Model Info: {'layers': {'input': 1, 'hidden1': 60, 'output': 1, 'hidden2': 60}, 'loss': 'mse', 'learning_rate': 0.1, 'look_ahead': 5, 'batch_size': 363, 'self': <models.lstm.StatefulMultiStepLSTM object at 0x7f08c6bfaad0>, 'look_back': 3, 'dropout': 0.1}
2017-05-25 20:18:41,321. Compilation Time : 0.0297451019287
2017-05-25 20:18:41,408. Training...
2017-05-25 20:20:32,150. Training duration (s) : 110.741152048
2017-05-25 20:20:32,150. Training Loss per epoch: [1.681851084344089, 0.24788869777694345, 0.19641943322494626, 0.18119888962246478, 0.17181257531046867, 0.16298708878457546, 0.15975677547976375, 0.15461506973952055, 0.15103128179907799, 0.14764749491587281, 0.1472747188527137, 0.14339367137290537, 0.14283517911098897, 0.13769937749020755, 0.13583468785509467, 0.13662779750302434, 0.1321789612993598, 0.13268032530322671, 0.13176460331305861, 0.13355643046088517, 0.1305908274371177, 0.12923583178780973, 0.12567584379576147, 0.12652167002670467, 0.12611427786760032, 0.12515893741510808, 0.12563479738309979, 0.1243357895873487, 0.12199711962603033, 0.1233309677336365, 0.11901260400190949, 0.11996645550243556, 0.11969380197115242, 0.12172879581339657, 0.11937546846456826, 0.11721777776256204, 0.11710855853743851, 0.11774927005171776, 0.11638905853033066, 0.11628759372979403, 0.11468136333860457, 0.11609931499697268, 0.11453231913037598, 0.11322964634746313, 0.11264469986781478, 0.1108244857750833, 0.11131957662291825, 0.11192723549902439, 0.11287318845279515, 0.11310212803073227, 0.11135042947717011, 0.11200372036546469, 0.11064658127725124, 0.11075551644898951, 0.10832354892045259, 0.10980218579061329, 0.10813198331743479, 0.10956925828941166, 0.10642905556596816, 0.11058834567666054, 0.10694219567812979, 0.10882816440425813, 0.10725958039984107, 0.10749708325602114, 0.10792173980735242, 0.10765618621371686, 0.10601341794244945, 0.10687973094172776, 0.10617560381069779, 0.10673096892423928, 0.1044313448946923, 0.10791590181179345, 0.10681095626205206, 0.10740753263235092, 0.1064254161901772, 0.10419251304119825, 0.10395475965924561, 0.10340923094190657, 0.10595294320955873, 0.10277637699618936, 0.10480691585689783, 0.10199858248233795, 0.10318024479784071, 0.10393365821801126, 0.10373162105679512, 0.10230897483415902, 0.103138581616804, 0.10452512931078672, 0.10411519557237625, 0.10311331041157246, 0.10226640338078141, 0.10122654028236866, 0.1030129874125123, 0.10228489059954882, 0.10304215038195252, 0.10130464751273394, 0.10123215150088072, 0.10114802233874798, 0.10119700338691473, 0.10003186669200659]
2017-05-25 20:20:32,150. Validation  Loss per epoch: [0.30018413563569385, 0.20086294909318289, 0.18075448771317801, 0.16436824202537537, 0.15877486765384674, 0.15527642269929251, 0.15215791761875153, 0.14801597595214844, 0.14628015955289206, 0.14373635252316794, 0.14172312120596567, 0.14060577750205994, 0.13783262670040131, 0.1358694757024447, 0.13479461769262949, 0.13352735588947931, 0.13177115221818289, 0.13065698246161142, 0.1290183812379837, 0.12673052400350571, 0.12612599631150564, 0.12457663814226787, 0.12311996767918269, 0.12122482309738795, 0.12064347912867864, 0.12005428473154704, 0.11839357763528824, 0.11648839960495631, 0.11621078352133433, 0.11544438699881236, 0.11403590937455495, 0.1129807357986768, 0.11195002247889836, 0.11122623831033707, 0.11105271925528844, 0.10987007617950439, 0.10863147675991058, 0.10847194244464238, 0.10686417420705159, 0.10637943198283513, 0.10640262812376022, 0.10482439895470937, 0.10476664453744888, 0.10368691136439641, 0.10398734857638676, 0.10328663637240727, 0.10247526069482167, 0.10183002551396687, 0.10140292346477509, 0.10054255276918411, 0.10034240782260895, 0.10014313211043675, 0.099577431877454117, 0.099612404902776078, 0.09902036190032959, 0.098566172023614243, 0.097679309546947479, 0.09764484564463298, 0.096681691706180573, 0.096642243365446731, 0.096274316310882568, 0.096471617619196579, 0.095548011362552643, 0.095530492564042405, 0.095335955421129867, 0.095063361028830215, 0.095153945187727615, 0.094620245198408767, 0.0939405436317126, 0.093528566261132554, 0.094118632376194, 0.093746677041053772, 0.093818070987860366, 0.093401342630386353, 0.092878920336564377, 0.093227701882521316, 0.093187324702739716, 0.092584654688835144, 0.092521240313847855, 0.09223128606875737, 0.092145994305610657, 0.091640911996364594, 0.091501509149869278, 0.091284915804862976, 0.091127162178357438, 0.090647963186105088, 0.090260999898115798, 0.090523339807987213, 0.090656193594137832, 0.09033975501855214, 0.090266473591327667, 0.090354104836781815, 0.08979024986426036, 0.089935059348742172, 0.089866943657398224, 0.089401779075463608, 0.089614274601141616, 0.089659643669923142, 0.089190281927585602, 0.089018200834592179]
2017-05-25 20:20:42,063. Validation2 Loss 0.337520707112
2017-05-25 20:20:42,227. Test Loss 0.339369262067
2017-05-25 20:20:42,825. Train RMSE on 1 timestep prediction 0.027592
2017-05-25 20:20:42,827. Train RMSE on 2 timestep prediction 0.036503
2017-05-25 20:20:42,827. Train RMSE on 3 timestep prediction 0.045102
2017-05-25 20:20:42,827. Train RMSE on 4 timestep prediction 0.052564
2017-05-25 20:20:42,827. Train RMSE on 5 timestep prediction 0.060044
2017-05-25 20:20:42,828.  Train RMSE Naive One Timestep Shift 0.020872
2017-05-25 20:21:57,913. Validation1 RMSE on 1 timestep prediction 0.031064
2017-05-25 20:21:57,913. Validation1 RMSE on 2 timestep prediction 0.037720
2017-05-25 20:21:57,914. Validation1 RMSE on 3 timestep prediction 0.045039
2017-05-25 20:21:57,914. Validation1 RMSE on 4 timestep prediction 0.052089
2017-05-25 20:21:57,914. Validation1 RMSE on 5 timestep prediction 0.059464
2017-05-25 20:21:57,914.  Validation1 RMSE Naive One Timestep Shift 0.020273
2017-05-25 20:22:08,878. Validation2 RMSE on 1 timestep prediction 0.063739
2017-05-25 20:22:08,879. Validation2 RMSE on 2 timestep prediction 0.079089
2017-05-25 20:22:08,879. Validation2 RMSE on 3 timestep prediction 0.092020
2017-05-25 20:22:08,879. Validation2 RMSE on 4 timestep prediction 0.100272
2017-05-25 20:22:08,879. Validation2 RMSE on 5 timestep prediction 0.105253
2017-05-25 20:22:08,879.  Validation2 RMSE Naive One Timestep Shift 0.034259
2017-05-25 20:22:29,030. Test RMSE on 1 timestep prediction 0.063688
2017-05-25 20:22:29,030. Test RMSE on 2 timestep prediction 0.079213
2017-05-25 20:22:29,030. Test RMSE on 3 timestep prediction 0.092278
2017-05-25 20:22:29,031. Test RMSE on 4 timestep prediction 0.100629
2017-05-25 20:22:29,031. Test RMSE on 5 timestep prediction 0.105678
2017-05-25 20:22:29,031.  Test RMSE Naive One Timestep Shift 0.034259
2017-05-25 20:22:34,077. -------------------------run complete----------------------------------------------
2017-05-25 20:22:34,077. 

